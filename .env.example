# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2-vision

# Whisper Configuration (MLX-accelerated)
# MLX automatically uses GPU acceleration on Apple Silicon (M1/M2/M3)
# Performance: ~25 min for 1-hour video with medium model
WHISPER_MODEL=medium  # Options: tiny, base, small, medium, large, turbo

# Speaker Diarization (pyannote.audio)
# Get your token from: https://huggingface.co/settings/tokens
# Required models: pyannote/speaker-diarization-3.1, pyannote/segmentation-3.0
HF_TOKEN=your_huggingface_token_here

# Output Configuration
OUTPUT_DIR=./output
FRAME_EXTRACTION_FPS=1  # Extract 1 frame per second
